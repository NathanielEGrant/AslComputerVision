# ASL Alphabet Computer Vision ğŸ¤Ÿ

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/) 
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)](https://www.tensorflow.org/) 
[![Streamlit](https://img.shields.io/badge/Streamlit-ğŸ“Š-brightgreen.svg)](https://streamlit.io/)

A deployable **machine learning + computer vision project** that interprets the **ASL alphabet** from live video input and displays the predicted letter in real time.

![demo](assets/demo.gif)

## âœ¨ Features
- ğŸ“Š **Deep Learning Model** trained on ASL alphabet dataset (MobileNetV2 backbone)  
- ğŸ–ï¸ **Hand Tracking** with [MediaPipe](https://mediapipe.dev/)  
- ğŸ¥ **Real-time Inference** via OpenCV + optional Streamlit UI  
- ğŸ’¾ **TFLite Export** for lightweight deployment 

## ğŸ§± Tech Stack
- Python â€¢ TensorFlow/Keras â€¢ MediaPipe â€¢ OpenCV â€¢ Streamlit

## ğŸ—‚ï¸ Data
- Project was trained using [ASL Alphabet Dataset](https://www.kaggle.com/datasets/debashishsau/aslamerican-sign-language-aplhabet-dataset)
- dataset has about 7500 images per label
- Labels include A-Z, nothing, delete, and space.

## ğŸ“Š Results
- Achieved **91%** on held-out validation set
- Stable **hand detection** using MediaPipe landmarks  
- Correctly labeled ASL alphabet signs with confidence overlay

## ğŸ§  How It Works (overview)
- **MediaPipe** locates the hand and creates a bounding box
- Cropped hand images are **preprocessed** (224Ã—224, normalized)
- A **CNN classifier** predicts the ASL letter (Aâ€“Z)

## ğŸ›£ï¸ Roadmap
- Export TFLite and measure CPU latency
- Improve noisy background robustness
- Improve low-light robustness
- Expand to dynamic signs (words)

---
Created by **Nathaniel Grant**
